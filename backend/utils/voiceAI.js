// utils/voiceAI.js - Voice-first interaction using Vertex AI Speech services
import speech from '@google-cloud/speech';
import textToSpeech from '@google-cloud/text-to-speech';
import { generativeModel } from './vertex.js';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Initialize Speech-to-Text client
const speechClient = new speech.SpeechClient();

// Initialize Text-to-Speech client
const ttsClient = new textToSpeech.TextToSpeechClient();

// Supported languages/dialects for Indian farmers
const SUPPORTED_LANGUAGES = {
  'hi-IN': 'Hindi',
  'en-IN': 'English (India)',
  'bn-IN': 'Bengali',
  'te-IN': 'Telugu',
  'mr-IN': 'Marathi',
  'ta-IN': 'Tamil',
  'gu-IN': 'Gujarati',
  'kn-IN': 'Kannada',
  'ml-IN': 'Malayalam',
  'pa-IN': 'Punjabi',
  'or-IN': 'Odia'
};

/**
 * Convert speech audio buffer to text using Vertex AI Speech-to-Text
 * @param {Buffer} audioBuffer - Audio file buffer
 * @param {string} languageCode - Language code (e.g., 'hi-IN', 'en-IN')
 * @param {string} encoding - Audio encoding (e.g., 'WEBM_OPUS', 'MP3', 'WAV')
 * @param {number} sampleRateHertz - Sample rate of audio
 * @returns {Promise<string>} Transcribed text
 */
async function speechToText(audioBuffer, languageCode = 'hi-IN', encoding = 'WEBM_OPUS', sampleRateHertz = 48000) {
  try {
    // Enhanced request configuration for better recognition
    const request = {
      audio: {
        content: audioBuffer.toString('base64'),
      },
      config: {
        encoding: encoding,
        sampleRateHertz: sampleRateHertz,
        languageCode: languageCode,
        alternativeLanguageCodes: ['en-IN', 'hi-IN'], // Fallback languages
        enableAutomaticPunctuation: true,
        enableWordTimeOffsets: false,
        model: 'latest_long', // Use latest model for better accuracy
        useEnhanced: true, // Enhanced model for better accuracy
        maxAlternatives: 1,
        speechContexts: [
          {
            phrases: [
              "farming", "crop", "disease", "pest", "fertilizer", "irrigation", "harvest", "seed", "soil", "weather",
              "wheat", "rice", "cotton", "tomato", "potato", "onion", "maize", "sugarcane", "millet",
              "yellowing", "wilting", "spots", "insects", "fungus", "drought", "water", "market", "price"
            ],
            boost: 20.0
          }
        ]
      },
    };

    console.log(`üé§ Processing speech in ${SUPPORTED_LANGUAGES[languageCode] || languageCode}...`);
    console.log(`üìä Audio buffer size: ${audioBuffer.length} bytes`);
    
    const [response] = await speechClient.recognize(request);
    
    if (!response.results || response.results.length === 0) {
      console.log('‚ö†Ô∏è No speech detected in audio');
      throw new Error('No speech detected in the audio. Please speak clearly and try again.');
    }
    
    const transcription = response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n')
      .trim();

    if (!transcription || transcription.length === 0) {
      console.log('‚ö†Ô∏è Empty transcription received');
      throw new Error('Could not understand the speech. Please speak clearly and try again.');
    }

    console.log(`üìù Transcribed text: "${transcription}"`);
    console.log(`üéØ Confidence: ${response.results[0]?.alternatives[0]?.confidence || 'N/A'}`);
    
    return transcription;
  } catch (error) {
    console.error('Speech-to-Text error:', error);
    
    // Enhanced error handling
    if (error.code === 3) { // INVALID_ARGUMENT
      throw new Error('Audio format not supported. Please check your microphone settings.');
    } else if (error.code === 7) { // PERMISSION_DENIED
      throw new Error('Speech recognition service not available. Using demo mode.');
    } else if (error.code === 14) { // UNAVAILABLE
      throw new Error('Speech recognition service temporarily unavailable.');
    }
    
    throw new Error(`Speech recognition failed: ${error.message}`);
  }
}

/**
 * Convert text to speech using Vertex AI Text-to-Speech
 * @param {string} text - Text to convert to speech
 * @param {string} languageCode - Language code for output speech
 * @param {string} voiceName - Specific voice name (optional)
 * @param {string} gender - Voice gender ('NEUTRAL', 'MALE', 'FEMALE')
 * @returns {Promise<Buffer>} Audio buffer
 */
async function convertTextToSpeech(text, languageCode = 'hi-IN', voiceName = null, gender = 'NEUTRAL') {
  try {
    // Voice configuration based on language
    const voiceConfig = {
      languageCode: languageCode,
      ssmlGender: gender,
    };

    // Use specific voice if provided, otherwise let Google choose
    if (voiceName) {
      voiceConfig.name = voiceName;
    }

    const request = {
      input: { text: text },
      voice: voiceConfig,
      audioConfig: {
        audioEncoding: 'MP3',
        speakingRate: 1.3, // Fast for super brief responses
        pitch: 0.0,
        volumeGainDb: 0.0,
      },
    };

    console.log(`üîä Generating speech in ${SUPPORTED_LANGUAGES[languageCode] || languageCode}...`);
    
    const [response] = await ttsClient.synthesizeSpeech(request);
    console.log('‚úÖ Speech generated successfully');
    
    return response.audioContent;
  } catch (error) {
    console.error('Text-to-Speech error:', error);
    throw new Error(`Speech synthesis failed: ${error.message}`);
  }
}

/**
 * Process farmer's voice query using AI and return voice response
 * @param {Buffer} audioBuffer - Input audio from farmer
 * @param {string} inputLanguage - Farmer's language
 * @param {object} context - Additional context (location, crop, etc.)
 * @returns {Promise<{text: string, audio: Buffer, language: string}>}
 */
async function processVoiceQuery(audioBuffer, inputLanguage = 'hi-IN', context = {}) {
  try {
    // Step 1: Convert speech to text
    const userQuery = await speechToText(audioBuffer, inputLanguage);
    
    if (!userQuery || userQuery.trim().length === 0) {
      throw new Error('Could not understand the audio. Please try again.');
    }

    // Step 2: Create enhanced prompt for AI with agricultural context
    const enhancedPrompt = createAgriculturalPrompt(userQuery, context, inputLanguage);
    
    // Step 3: Get AI response using Vertex AI
    console.log('ü§ñ Processing with Vertex AI...');
    const result = await generativeModel.generateContent(enhancedPrompt);
    let aiResponse = result.response.candidates[0].content.parts[0].text;
    
    // Step 3.5: Ensure response is concise and within limits
    aiResponse = optimizeResponseLength(aiResponse, inputLanguage);
    
    console.log(`üí¨ AI Response: ${aiResponse}`);

    // Step 4: Convert AI response back to speech
    const responseAudio = await convertTextToSpeech(aiResponse, inputLanguage);
    
    return {
      userQuery: userQuery,
      text: aiResponse,
      audio: responseAudio,
      language: inputLanguage,
      timestamp: new Date().toISOString()
    };
    
  } catch (error) {
    console.error('Voice query processing error:', error);
    
    // Generate error message in user's language
    const errorMessage = getErrorMessage(inputLanguage);
    const errorAudio = await convertTextToSpeech(errorMessage, inputLanguage);
    
    return {
      userQuery: '',
      text: errorMessage,
      audio: errorAudio,
      language: inputLanguage,
      error: true,
      timestamp: new Date().toISOString()
    };
  }
}

/**
 * Create agricultural-focused prompt for better AI responses
 */
function createAgriculturalPrompt(userQuery, context, languageCode) {
  const language = SUPPORTED_LANGUAGES[languageCode] || 'English';
  
  return `You are "FarmMitra" (‡§´‡§æ‡§∞‡•ç‡§Æ ‡§Æ‡§ø‡§§‡•ç‡§∞), an expert agricultural advisor with 20+ years of experience helping Indian farmers. You understand:

üåæ CROPS: Wheat, Rice, Cotton, Sugarcane, Corn, Vegetables, Fruits, Pulses, Oilseeds
üêõ PESTS: Bollworm, Aphids, Whitefly, Stem borer, Leaf curl virus, Bacterial blight
üíä TREATMENTS: Neem oil, Copper fungicide, Imidacloprid, Carbendazim, Bio-pesticides
üå± SEASONS: Kharif (June-Oct), Rabi (Nov-April), Zaid (April-June)
üåßÔ∏è WEATHER: Monsoon patterns, drought management, flood protection
üí∞ SCHEMES: PM-KISAN, Crop insurance, Soil health cards, DBT

FARMER CONTEXT:
Location: ${context.location || 'India'} | Season: ${context.season || 'Current'} | Crop: ${context.crop || 'Mixed farming'} | Experience: ${context.experience || 'Moderate'}

FARMER'S QUESTION: "${userQuery}"

ANALYSIS: First, identify if this is about:
- Pest/Disease (symptoms, treatment, prevention)
- Crop Management (planting, irrigation, harvesting)
- Market/Prices (selling, buying, storage)
- Weather/Climate (rain, drought, temperature)
- Government Schemes (subsidies, loans, insurance)
- General Farming (seeds, fertilizers, equipment)

CRITICAL RESPONSE RULES:
‚úÖ Use ONLY ${language} language 
‚úÖ Maximum 20-30 words TOTAL
‚úÖ Give ONLY 1-2 actions
‚úÖ NO greetings, NO long introductions
‚úÖ Direct answer ONLY

STRICT FORMAT:
"[problem]. ‡§ï‡§∞‡•á‡§Ç: [action]. ‡§≤‡§æ‡§ó‡§§: [cost]."

EXAMPLE: "‡§™‡§§‡•ç‡§§‡•Ä ‡§™‡•Ä‡§≤‡•Ä ‡§π‡•à‡•§ ‡§Ø‡•Ç‡§∞‡§ø‡§Ø‡§æ 10kg ‡§õ‡§ø‡§°‡§º‡§ï‡•á‡§Ç‡•§ ‡§≤‡§æ‡§ó‡§§: 200 ‡§∞‡•Å‡§™‡§Ø‡•á‡•§"

WORD LIMIT: 30 WORDS MAXIMUM - COUNT EVERY WORD!

Respond in ${language} (MAX 30 WORDS):`;
}

/**
 * Optimize response length to ensure concise, efficient answers
 */
function optimizeResponseLength(response, languageCode) {
  // Remove excessive whitespace and line breaks
  let optimized = response.replace(/\s+/g, ' ').trim();
  
  // Word count limits based on language (approximate)
  const MAX_WORDS = {
    'hi-IN': 25,     // Hindi - super compact
    'en-IN': 30,     // English - slightly longer
    'bn-IN': 25,     // Bengali
    'te-IN': 25,     // Telugu
    'mr-IN': 25,     // Marathi
    'ta-IN': 25,     // Tamil
    'gu-IN': 25,     // Gujarati
    'kn-IN': 25,     // Kannada
    'ml-IN': 25,     // Malayalam
    'pa-IN': 25,     // Punjabi
    'or-IN': 25      // Odia
  };
  
  const maxWords = MAX_WORDS[languageCode] || 30;
  const words = optimized.split(' ');
  
  // If response is too long, truncate aggressively
  if (words.length > maxWords) {
    const truncated = words.slice(0, maxWords - 2).join(' ');
    
    // Add brief ending based on language
    const endings = {
      'hi-IN': '... ‡§î‡§∞?',
      'en-IN': '... more?',
      'bn-IN': '... ‡¶Ü‡¶∞‡ßã?',
      'te-IN': '... ‡∞Æ‡∞∞‡∞ø‡∞Ç‡∞§?',
      'mr-IN': '... ‡§Ö‡§ß‡§ø‡§ï?',
      'ta-IN': '... ‡ÆÆ‡Øá‡Æ≤‡ØÅ‡ÆÆ‡Øç?',
      'gu-IN': '... ‡™µ‡™ß‡´Å?',
      'kn-IN': '... ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≥Å?',
      'ml-IN': '... ‡¥ï‡µÇ‡¥ü‡µÅ‡¥§‡µΩ?',
      'pa-IN': '... ‡®π‡©ã‡®∞?',
      'or-IN': '... ‡¨Ö‡¨ß‡¨ø‡¨ï?'
    };
    
    optimized = truncated + (endings[languageCode] || endings['en-IN']);
  }
  
  // Remove redundant phrases and filler words aggressively
  const fillerPhrases = {
    'hi-IN': [
      '‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ', '‡§Ü‡§™‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ', '‡§ú‡•à‡§∏‡§æ ‡§ï‡§ø', '‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ', '‡§Ø‡§π ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à ‡§ï‡§ø',
      '‡§®‡§Æ‡§∏‡•ç‡§§‡•á', '‡§π‡•à‡§≤‡•ã', '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§Ü‡§™‡§ï‡§æ', '‡§∏‡•ç‡§µ‡§æ‡§ó‡§§', '‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à', '‡§∂‡§æ‡§Ø‡§¶',
      '‡§∏‡§Ç‡§≠‡§µ‡§§‡§É', '‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á', '‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤', '‡§µ‡§æ‡§∏‡•ç‡§§‡§µ ‡§Æ‡•á‡§Ç', '‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§µ‡§æ‡§≤'
    ],
    'en-IN': [
      'I understand', 'your problem', 'as you know', 'in addition', 'it is important that',
      'hello', 'hi', 'thank you', 'welcome', 'I think', 'maybe', 'probably',
      'definitely', 'absolutely', 'really', 'good question'
    ],
  };
  
  const fillers = fillerPhrases[languageCode] || [];
  fillers.forEach(filler => {
    optimized = optimized.replace(new RegExp(filler, 'gi'), '');
  });
  
  // Clean up extra spaces
  optimized = optimized.replace(/\s+/g, ' ').trim();
  
  console.log(`üìè Response optimized: ${words.length} ‚Üí ${optimized.split(' ').length} words`);
  
  return optimized;
}

/**
 * Get error messages in different languages
 */
function getErrorMessage(languageCode) {
  const errorMessages = {
    'hi-IN': '‡§Æ‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§™‡§∞‡•á‡§∂‡§æ‡§®‡•Ä ‡§π‡•Å‡§à ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§',
    'en-IN': 'Sorry, I had trouble understanding you. Please try again.',
    'bn-IN': '‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶•‡¶æ ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§',
    'te-IN': '‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞Æ‡±Ä ‡∞Æ‡∞æ‡∞ü ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ö‡±á‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç‡∞≤‡±ã ‡∞®‡∞æ‡∞ï‡±Å ‡∞á‡∞¨‡±ç‡∞¨‡∞Ç‡∞¶‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§',
    'mr-IN': '‡§Æ‡§æ‡§´ ‡§ï‡§∞‡§æ, ‡§Æ‡§≤‡§æ ‡§§‡•Å‡§Æ‡§ö‡•á ‡§Æ‡•ç‡§π‡§£‡§£‡•á ‡§∏‡§Æ‡§ú‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ö‡§°‡§ö‡§£ ‡§Ü‡§≤‡•Ä ‡§Ü‡§π‡•á. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.',
    'ta-IN': '‡ÆÆ‡Æ©‡Øç‡Æ©‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç, ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡Øá‡Æö‡Øç‡Æö‡Øà‡Æ™‡Øç ‡Æ™‡ØÅ‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡ØÅ‡Æï‡Øä‡Æ≥‡Øç‡Æµ‡Æ§‡Æø‡Æ≤‡Øç ‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ ‡Æö‡Æø‡Æ∞‡ÆÆ‡ÆÆ‡Øç ‡Æè‡Æ±‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.',
    'gu-IN': '‡™Æ‡™æ‡™´ ‡™ï‡™∞‡™∂‡´ã, ‡™Æ‡™®‡´á ‡™§‡™Æ‡™æ‡™∞‡´Ä ‡™µ‡™æ‡™§ ‡™∏‡™Æ‡™ú‡™µ‡™æ‡™Æ‡™æ‡™Ç ‡™Æ‡´Å‡™∂‡´ç‡™ï‡´á‡™≤‡´Ä ‡™™‡™°‡´Ä ‡™õ‡´á. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™´‡™∞‡´Ä‡™•‡´Ä ‡™™‡´ç‡™∞‡™Ø‡™æ‡™∏ ‡™ï‡™∞‡´ã.',
    'kn-IN': '‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤∞‡≥ç‡≤• ‡≤Æ‡≤æ‡≤°‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≥Å‡≤µ‡≤≤‡≥ç‡≤≤‡≤ø ‡≤®‡≤®‡≤ó‡≥Ü ‡≤§‡≥ä‡≤Ç‡≤¶‡≤∞‡≥Ü ‡≤Ü‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.',
    'ml-IN': '‡¥ï‡µç‡¥∑‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡¥£‡¥Ç, ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥∏‡¥Ç‡¥∏‡¥æ‡¥∞‡¥Ç ‡¥Æ‡¥®‡¥∏‡µç‡¥∏‡¥ø‡¥≤‡¥æ‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥¨‡µÅ‡¥¶‡µç‡¥ß‡¥ø‡¥Æ‡µÅ‡¥ü‡µç‡¥ü‡µç ‡¥â‡¥£‡µç‡¥ü‡¥æ‡¥Ø‡¥ø. ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‡¥∂‡µç‡¥∞‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.',
    'pa-IN': '‡®Æ‡®æ‡®´‡®º ‡®ï‡®∞‡®®‡®æ, ‡®Æ‡©à‡®®‡©Ç‡©∞ ‡®§‡©Å‡®π‡®æ‡®°‡©Ä ‡®ó‡©±‡®≤ ‡®∏‡®Æ‡®ù‡®£ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡©Å‡®∏‡®º‡®ï‡®≤ ‡®π‡©ã‡®à ‡®π‡©à‡•§ ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®ï‡©ã‡®∏‡®º‡®ø‡®∏‡®º ‡®ï‡®∞‡©ã‡•§',
    'or-IN': '‡¨¶‡≠Å‡¨É‡¨ñ‡¨ø‡¨§, ‡¨Æ‡≠Å‡¨Å ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï ‡¨ï‡¨•‡¨æ ‡¨¨‡≠Å‡¨ù‡¨ø‡¨¨‡¨æ‡¨∞‡≠á ‡¨Ö‡¨∏‡≠Å‡¨¨‡¨ø‡¨ß‡¨æ ‡¨≠‡≠ã‡¨ó‡≠Å‡¨õ‡¨ø‡•§ ‡¨¶‡≠ü‡¨æ‡¨ï‡¨∞‡¨ø ‡¨™‡≠Å‡¨®‡¨∞‡≠ç‡¨¨‡¨æ‡¨∞ ‡¨ö‡≠á‡¨∑‡≠ç‡¨ü‡¨æ ‡¨ï‡¨∞‡¨®‡≠ç‡¨§‡≠Å‡•§'
  };
  
  return errorMessages[languageCode] || errorMessages['en-IN'];
}

/**
 * Get available voices for a language
 */
async function getAvailableVoices(languageCode) {
  try {
    const [result] = await ttsClient.listVoices({ languageCode });
    return result.voices.filter(voice => voice.languageCodes.includes(languageCode));
  } catch (error) {
    console.error('Error fetching voices:', error);
    return [];
  }
}

/**
 * Save voice interaction to file for debugging/logging
 */
async function saveVoiceInteraction(interaction, filename) {
  try {
    const logsDir = path.join(__dirname, '../logs');
    if (!fs.existsSync(logsDir)) {
      fs.mkdirSync(logsDir, { recursive: true });
    }
    
    const logFile = path.join(logsDir, `voice_${filename}_${Date.now()}.json`);
    fs.writeFileSync(logFile, JSON.stringify(interaction, null, 2));
    
    if (interaction.audio) {
      const audioFile = path.join(logsDir, `voice_${filename}_${Date.now()}.mp3`);
      fs.writeFileSync(audioFile, interaction.audio);
    }
  } catch (error) {
    console.error('Error saving voice interaction:', error);
  }
}

export {
  speechToText,
  convertTextToSpeech as textToSpeech,
  processVoiceQuery,
  getAvailableVoices,
  saveVoiceInteraction,
  SUPPORTED_LANGUAGES
};
